{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data frames: Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flights = pd.read_csv('./data/flight_sample.csv')\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights['AIRLINE'] == 'AA')\n",
    "aa_flights = flights[ flights['AIRLINE'] == 'AA' ]\n",
    "aa_flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_count2 = np.sum(flights['AIRLINE'] == 'AA')\n",
    "\n",
    "print(np.sum(flights['AIRLINE'] == 'AA'))\n",
    "print((flights['AIRLINE'] == 'AA').sum())\n",
    "print( \"there are {} AA flights in the set\".format(flight_count2))\n",
    "# why do we use sum() ^^\n",
    "print(aa_flights.shape)\n",
    "print(aa_flights.shape[0])\n",
    "aa_flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_flights_long = flights[ (flights['AIRLINE'] == 'AA') & (flights['DISTANCE'] > 1000) ]\n",
    "# what if you wanted to filter on flights less than 1000 or greater than 2000?\n",
    "aa_flights_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is broadcasting and how does it explain this result?\n",
    "aa_flights.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aa_flights['TAXI_OUT'].max())\n",
    "\n",
    "print(\"%%%%%%%%%%%%%%%\")\n",
    "print(aa_flights[['TAXI_OUT', 'TAXI_IN']].max())\n",
    "\n",
    "# how is this different than above? Why is this not great?\n",
    "print(\"%%%%%%%%%%%%%%%\")\n",
    "print(aa_flights.max()[['TAXI_OUT', 'TAXI_IN']])\n",
    "\n",
    "print(\"%%%%%%%%%%%%%%%\")\n",
    "print(aa_flights.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique list of Airlines\n",
    "print(flights['AIRLINE'].unique())\n",
    "\n",
    "# get count of unique airlines\n",
    "print(len(flights['AIRLINE'].unique()))\n",
    "print(flights['AIRLINE'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregate()\n",
    "\n",
    "What was the aggregate() function and how was it more flexible than just calling mean() or median(). Wasn't there something about renaming columns as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dataframes: Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('./data/college-scorecard-data-scrubbed.csv', encoding='latin-1')\n",
    "# what if you want to set the index as you load the data frame ^^\n",
    "# what does 'encoding' do?\n",
    "\n",
    "scores.set_index('institution_name', inplace=True)\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('./data/college-scorecard-data-scrubbed.csv', encoding='latin-1')\n",
    "scores.set_index('institution_name', inplace=True)\n",
    "\n",
    "# use loc[] to access row (Panda Series) by index\n",
    "scores.loc['University of Notre Dame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drill down even further\n",
    "scores.loc['University of Notre Dame']['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are returning to this specific row, you can store it for easy access\n",
    "nd = scores.loc['University of Notre Dame']\n",
    "print(\"Notre Dame's top sat reading and math percentile is {} and {} respectively...\".format(\n",
    "        nd['sat_reading_75'], \n",
    "        nd['sat_math_75'])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can slice via index with both numerical values and strings (also dates)\n",
    "# what is different between implicit and explicit indexes when slicing?\n",
    "scores.loc['University of Chicago':'University of Notre Dame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('./data/college-scorecard-data-scrubbed.csv', encoding='latin-1')\n",
    "scores_multi_indexed = scores.set_index(['state', 'institution_name'])\n",
    "scores_multi_indexed\n",
    "# scores_multi_indexed.loc['IN']\n",
    "# scores_multi_indexed.loc['MI']\n",
    "# scores_multi_indexed.loc['IN'].loc['University of Notre Dame']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping and Filling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('./data/college-scorecard-data-scrubbed.csv', encoding='latin-1', index_col=\"institution_name\")\n",
    "# Dropping columns\n",
    "print(\"Shape of entire scores DF\", scores.shape)\n",
    "\n",
    "# scores.drop('white_percentage', inplace=True, axis=1)\n",
    "# scores.drop(['black_percentage',\n",
    "#        'hispanic_percent', 'asian_precent',\n",
    "#        'american_indian_or_alaskan_native_precent',\n",
    "#        'native_hawaiian_pacific_islander_percentage',\n",
    "#        'two_or_more_races_percentage', 'non_resident_alients_percentage',\n",
    "#        'unknown_percentage'], inplace=True, axis=1)\n",
    "\n",
    "# print(scores.shape)\n",
    "# scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with just a subset, this might be esasier\n",
    "scores_small = scores[['city','state','url', 'predominant_degree_desc', 'sat_math_25', 'sat_reading_25', 'sat_math_75', 'sat_reading_75']].copy(deep=True)\n",
    "print(scores_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many null values we have...\n",
    "scores_small.isnull().sum()\n",
    "\n",
    "# scores_small_clean = scores_small.dropna().copy()\n",
    "# print(scores_small.shape)\n",
    "# print(scores_small_clean.shape)\n",
    "# scores_small_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you drop na on a dataset, it will drop rows that have ANY missing data\n",
    "print(\"entire df\", scores.isnull().sum())\n",
    "print(\"\\nentire df\", scores.shape)\n",
    "print(\"\\ndrop all in entire df\", scores.dropna().shape)\n",
    "\n",
    "print(\"\\nsmall df\", scores_small.shape)\n",
    "scores_clean = scores_small.dropna().copy(deep=True)\n",
    "print(\"\\ndropna on entire 'clean'' df\", scores_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sat_math = int(scores_small['sat_math_75'].mean())\n",
    "print(avg_sat_math)\n",
    "scores_small['sat_math_75'].fillna(avg_sat_math, inplace=True)\n",
    "scores_small['sat_reading_75'].fillna(0, inplace=True)\n",
    "scores_small.fillna(scores_small.mean(), inplace=True)\n",
    "\n",
    "print(\"fillna() on entire small df\", scores_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_small.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composing New Series/Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column that totals the reading and math\n",
    "scores_clean['sat_total_75'] = scores_clean['sat_math_75'] + scores_clean['sat_reading_75']\n",
    "\n",
    "# get the overal average\n",
    "overall_sat_mean = scores_clean['sat_total_75'].mean()\n",
    "print(overall_sat_mean)\n",
    "\n",
    "# create a new column that diffs the total for each school\n",
    "scores_clean['sat_diff_75'] = scores_clean['sat_total_75'] - overall_sat_mean\n",
    "scores_clean.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idxmax() and idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_school = scores_clean['sat_diff_75'].idxmax()\n",
    "lowest_school = scores_clean['sat_diff_75'].idxmin()\n",
    "\n",
    "print(\"{} has the highest score with {} ({})\".format(highest_school, scores_clean.loc[highest_school]['sat_total_75'], scores_clean.loc[highest_school]['sat_diff_75']))\n",
    "\n",
    "low_school_data = scores_clean.loc[lowest_school]\n",
    "\n",
    "print(\"{} has the lowest score with {} ({})\".format(lowest_school, low_school_data['sat_total_75'], low_school_data['sat_diff_75']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores.loc[highest_school][['city', 'url', 'sat_reading_75', 'sat_reading_75']])\n",
    "print(scores.loc[lowest_school][['city', 'url', 'sat_reading_75', 'sat_reading_75']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Apply() to compose new columns in a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the column for summed sat scores\n",
    "scores_clean['sat_total_25'] = scores_clean['sat_math_25'] + scores_clean['sat_reading_25']\n",
    "\n",
    "# get overal average\n",
    "overall_sat_mean_25 = scores_clean['sat_total_25'].mean()\n",
    "\n",
    "def calculate_diff(total):\n",
    "    return total - overall_sat_mean_25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function to calculate diff\n",
    "scores_clean['sat_diff_25'] = scores_clean['sat_total_25'].apply(calculate_diff)\n",
    "\n",
    "highest_score = scores_clean['sat_diff_25'].idxmax()\n",
    "lowest_score = scores_clean['sat_diff_25'].idxmin()\n",
    "\n",
    "print(\"{} has the highest score with {} ({})\".format(highest_score, scores_clean.loc[highest_score]['sat_total_25'], scores_clean.loc[highest_score]['sat_diff_25']))\n",
    "\n",
    "low_school = scores_clean.loc[lowest_score]\n",
    "\n",
    "print(\"{} has the lowest score with {} ({})\".format(lowest_score, low_school['sat_total_25'], low_school['sat_diff_25']))\n",
    "scores_clean.head()\n",
    "\n",
    "nd = scores_clean.loc['University of Notre Dame']\n",
    "print(\"by the way... Notre dames numbers are 75: {} | {} and 25: {} | A diff of {}\".format(int(nd['sat_total_75']), int(nd['sat_diff_75']), int(nd['sat_total_25']), int(nd['sat_diff_25'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv('./data/flight_sample.csv')\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple group by\n",
    "flights_by_airline = flights.groupby(['AIRLINE'])\n",
    "flights_by_airline.groups\n",
    "# flights_by_airline.head()\n",
    "# flights_by_airline.mean()\n",
    "# flights_by_airline.mean().loc['AA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by on mulitple columns\n",
    "flights_by_airline_and_month = flights.groupby(['AIRLINE', 'MONTH'])\n",
    "flights_by_airline_and_month.max()[:5]\n",
    "\n",
    "# flights_by_airline_and_month.mean().loc['AA'].loc[3]\n",
    "# flights_by_airline_and_month.mean().loc['AA',3]\n",
    "# flights_by_airline_and_month.mean().loc['AA'].loc[3:9]['DISTANCE']\n",
    "# flights_by_airline_and_month.mean().loc['AA'].loc[3:9]['DISTANCE'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the longest flight AA flew in July 2015 \n",
    "# and now much longer (or shorter) than in December of that year\n",
    "\n",
    "print(\"July: \", flights_by_airline_and_month.max().loc['AA', 7]['DISTANCE'])\n",
    "print(\"December: \", flights_by_airline_and_month.max().loc['AA', 12]['DISTANCE'])\n",
    "print(flights_by_airline_and_month.max().loc['AA', 7]['DISTANCE'] - flights_by_airline_and_month.max().loc['AA', 12]['DISTANCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How would you sort a dataframe by a specific column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_pvt = flights.pivot_table('DISTANCE',index='DAY_OF_WEEK', columns = 'AIRLINE')\n",
    "# flight_pvt = flights.pivot_table('DISTANCE',index='DAY_OF_WEEK', columns = 'AIRLINE', aggfunc=[np.max, np.min])\n",
    "\n",
    "flight_pvt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goog = pd.read_csv(\"./data/Google_Stock_Price.csv\")\n",
    "goog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column to a date object\n",
    "goog['Date'] = pd.to_datetime(goog['Date'])\n",
    "print(goog.dtypes)\n",
    "\n",
    "goog.set_index('Date', inplace=True)\n",
    "goog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows based on year\n",
    "goog.loc['2007'][:3]\n",
    "\n",
    "# Get rows based on month\n",
    "goog.loc['March 2007'][:3]\n",
    "\n",
    "# Slice frame by date\n",
    "goog.loc['2007-3-23': '2008-3-23':7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goog_end_year = goog.asfreq('A')\n",
    "goog_end_year\n",
    "goog_avg = goog.resample('BM').mean()\n",
    "goog_avg\n",
    "goog_res = goog.resample('Q').mean().loc['2010': '2014']\n",
    "goog_res\n",
    "\n",
    "# what was that about rolling? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Line Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "# what is seaborn? what is it used for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster = pd.read_csv('./data/nd-football-2018-roster.csv', index_col='Number')\n",
    "roster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure,axes = plt.subplots()\n",
    "# what are the other ways to style the lines?\n",
    "axes.plot(roster.index, roster['Height'], label=\"Height\")\n",
    "\n",
    "# what are the different ways you can style the chart and legend?\n",
    "axes.set_xlabel('Jersy Number')\n",
    "axes.set_ylabel('Height')\n",
    "axes.set_title('Players by Height')\n",
    "axes.legend()\n",
    "\n",
    "\n",
    "# how do you limit the size of the x and y coordinates? 'xlim' something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure,axes = plt.subplots(figsize=(12,6))\n",
    "axes.plot(roster.index, roster['Height'], label=\"Height\")\n",
    "axes.plot(roster.index, roster['Weight'], label=\"Weight\")\n",
    "\n",
    "axes.set_xlabel('Jersy Number')\n",
    "axes.set_ylabel('Height')\n",
    "axes.set_title('Players by Height and Weight')\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure,axes = plt.subplots(1,2, figsize=(12,6))\n",
    "axes[0].plot(roster.index, roster['Height'], label=\"Height\")\n",
    "\n",
    "axes[0].set_xlabel('Jersy Number')\n",
    "axes[0].set_ylabel('Height')\n",
    "axes[0].set_title('Players by Height')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(roster.index, roster['Weight'], label=\"Weight\", color='Green')\n",
    "\n",
    "axes[1].set_xlabel('Jersy Number')\n",
    "axes[1].set_ylabel('Weight')\n",
    "axes[1].set_title('Players by Weight')\n",
    "axes[1].legend()\n",
    "\n",
    "# What is sharey=True and when/why would you use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plots\n",
    "\n",
    "figure,axes = plt.subplots(figsize=(8,4))\n",
    "img = axes.scatter(\n",
    "    roster['Weight'], roster['Height'],\n",
    "    c=roster['Height'], cmap='coolwarm'\n",
    ")\n",
    "\n",
    "axes.set_title(\"Relationship between Weight and Height\")\n",
    "axes.set_xlabel('Height')\n",
    "axes.set_ylabel('Weight')\n",
    "\n",
    "figure.colorbar(img, label=\"the taller they get...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots()\n",
    "axes.hist(roster['Height'], bins=12)\n",
    "# what does bins do? In this case is 18 a good number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask with the OR bitwise operator\n",
    "roster[( roster['Class'] == 'Sr.') | (roster['Class'] == 'Jr.')][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots()\n",
    "upper = roster[( roster['Class'] == 'Sr.') | (roster['Class'] == 'Jr.')]\n",
    "under = roster[~( roster['Class'] == 'Sr.') & ~(roster['Class'] == 'Jr.')]\n",
    "\n",
    "axes.hist(upper['Weight'], label=\"Upper Classman\", alpha=1, color=\"blue\")\n",
    "axes.hist(under['Weight'], label=\"Under Classman\", alpha=.7, color=\"gold\")\n",
    "\n",
    "axes.legend()\n",
    "axes.set_title(\"Weight of Upper vs Under Classman\")\n",
    "axes.set_ylabel(\"Number of Players\")\n",
    "axes.set_xlabel(\"Weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_clean = flights.dropna()\n",
    "print(flights_clean.shape)\n",
    "\n",
    "figure, axes = plt.subplots()\n",
    "image = axes.hist2d(\n",
    "    flights_clean[ (flights_clean['AIRLINE'] == 'AA')]['DISTANCE'],\n",
    "    flights_clean[ (flights_clean['AIRLINE'] == 'AA')]['TAXI_OUT'],\n",
    "    cmin=1,\n",
    "    cmap='coolwarm'\n",
    ")\n",
    "\n",
    "axes.set_xlabel(\"Distane\")\n",
    "axes.set_ylabel(\"Taxi Out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_airline_and_month.sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gonna be using this...\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'July', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure,axes = plt.subplots()\n",
    "aa_flights = flights_by_airline_and_month.sum().loc['AA']\n",
    "axes.bar(range(len(aa_flights.index)), aa_flights['DISTANCE'])\n",
    "\n",
    "axes.set_xticks(range(len(aa_flights.index)))\n",
    "axes.set_xticklabels(months, rotation=70)\n",
    "\n",
    "axes.set_title('American Airlines Total Distance By Month')\n",
    "axes.set_ylabel('Total Distance')\n",
    "axes.set_xlabel('Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figure,axes = plt.subplots(figsize=(12,8))\n",
    "\n",
    "offset = .3\n",
    "axes.bar(np.arange(12) - offset, flights_by_airline_and_month.sum().loc['AA']['DISTANCE'], width=offset, label='American')\n",
    "axes.bar(np.arange(12), flights_by_airline_and_month.sum().loc['WN']['DISTANCE'], width=offset, label='Southwest')\n",
    "axes.bar(np.arange(12) + offset, flights_by_airline_and_month.sum().loc['HA']['DISTANCE'], width=offset, label='Hawaiian')\n",
    "\n",
    "axes.set_xticks(np.arange(12))\n",
    "axes.set_xticklabels(months, rotation=70)\n",
    "\n",
    "axes.set_title('American Airlines Total Distance By Month')\n",
    "axes.set_ylabel('Total Distance')\n",
    "axes.set_xlabel('Months')\n",
    "\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots()\n",
    "axes.plot(goog_avg.index, goog_avg['High'], label='High')\n",
    "axes.plot(goog_avg.index, goog_avg['Low'], label='Low')\n",
    "\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots()\n",
    "axes.plot(goog_res.index, goog_res['High'], label='High')\n",
    "axes.plot(goog_res.index, goog_res['Low'], label='Low')\n",
    "axes.set_xticks(goog_res.index)\n",
    "axes.set_xticklabels(goog_res.index, rotation=90)\n",
    "axes.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
